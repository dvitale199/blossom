# Blossom.ai MVP Technical Plan

## Executive Summary

This plan optimizes for **speed to learning** (getting real user feedback fast) while avoiding decisions that would be painful to reverse. Given your Python/GCP strengths and solo developer status, I'm recommending a stack that leans heavily on managed services for undifferentiated work while keeping your AI pipelineâ€”your core differentiatorâ€”fully custom.

---

## 1. Tech Stack Recommendation

### Frontend: **Next.js 14 + shadcn/ui + Tailwind**

**Why not Streamlit?** I know it's tempting given your experience, but Streamlit has real limitations for a consumer product:
- No fine-grained control over UX (students/parents expect polish)
- Session state management becomes painful
- File upload UX is clunky
- No offline/PWA capabilities
- Harder to add real-time features later

**Why Next.js specifically:**
- App Router gives you server components (great for AI streaming)
- API routes mean you could skip FastAPI initially if you want (but I don't recommend it)
- Vercel deployment is trivial
- shadcn/ui gives you beautiful, accessible components you copy-paste (not a dependency)
- Massive ecosystem = every problem has a solved example

**The learning curve trade-off:** You'll spend ~1-2 weeks getting comfortable, but the velocity payoff is worth it. Use v0.dev (Vercel's AI) to generate initial components.

**Alternatives considered:**
- *Remix*: Great, but smaller ecosystem. Pick if you want more control over data loading.
- *SvelteKit*: Lovely DX, but React has more resources for when you're stuck.
- *Streamlit*: Only if you want to ship in <2 weeks and accept you'll rewrite the frontend.

### Backend: **FastAPI (your existing strength)**

No reason to change. FastAPI is:
- Excellent for AI workloads (async, streaming support)
- Great OpenAPI docs for your frontend integration
- You already know it well

**Key packages to add:**
- `python-multipart` for file uploads
- `celery` or `arq` for background jobs (document processing)
- `anthropic` or `openai` SDK
- `PyMuPDF` (fitz) for PDF parsing
- `pydantic` v2 for validation

### Database: **Supabase (PostgreSQL + extras)**

**Why Supabase over raw Cloud SQL:**
- Gives you PostgreSQL (you know it)
- Includes auth (see below)
- Includes file storage (see below)
- Real-time subscriptions if you need them later
- Row Level Security for multi-tenant safety
- Generous free tier, predictable pricing
- Dashboard for debugging

**Why not a vector database (Pinecone, Weaviate)?** 
You don't need one yet. PostgreSQL with `pgvector` extension (included in Supabase) handles similarity search fine for MVP scale. Don't add infrastructure complexity until you prove you need it.

**âš ï¸ Hard-to-reverse decision:** Database choice is sticky. PostgreSQL is safeâ€”it's boring and that's good. If you started with MongoDB or a pure vector DB, migration would hurt.

### File Storage: **Supabase Storage (backed by S3)**

Consolidating with your database provider simplifies operations. Features you get:
- Signed URLs for secure uploads/downloads
- Image transformations (for thumbnails)
- Integrates with Row Level Security

Alternative: GCS is fine if you want to stay pure GCP. The integration work is similar.

### Auth: **Supabase Auth (included)**

**This is a strong "buy" decision.** Auth is:
- A solved problem with lots of edge cases
- A security liability if you build it wrong
- Not your differentiator

Supabase Auth gives you:
- Email/password, magic links, OAuth (Google is essential for students)
- Session management
- JWT tokens that work with your FastAPI backend
- User management UI

**Alternatives:**
- *Clerk*: More polished UI, better if you want social login profiles. Costs more.
- *Auth0*: Enterprise-grade, overkill for MVP.
- *Roll your own*: Don't. Seriously.

### AI/LLM Layer: **Anthropic Claude API (primary) + OpenAI (fallback)**

**Why Claude as primary:**
- Excellent at structured extraction (knowledge maps)
- Strong at educational content generation
- Vision capabilities for OCR built-in (no separate service needed!)
- Better at following complex instructions
- Slightly lower cost at Sonnet tier

**Architecture approach:**
```
User uploads PDF/image
    â†’ Claude Vision extracts text + structure
    â†’ Claude generates knowledge map JSON
    â†’ Stored in PostgreSQL
    â†’ Quiz generation pulls from knowledge map
    â†’ Claude evaluates responses
```

**Why have OpenAI as fallback:**
- Redundancy if either API has issues
- Some tasks (embeddings) might be cheaper with `text-embedding-3-small`
- Students need reliability

**Cost control strategies (detailed in section 6):**
- Use Haiku for simple tasks (quiz answer evaluation)
- Cache aggressively
- Batch operations where possible

### Deployment: **Cloud Run (backend) + Vercel (frontend)**

**Why split:**
- Vercel is unmatched for Next.js DX (preview deploys, edge functions, analytics)
- Cloud Run you already know for Python workloads
- Both have generous free tiers
- Both scale to zero (cost control)

**Alternative:** Put everything on Cloud Run. Works fine, slightly more config for Next.js, but keeps you in one ecosystem.

### Background Jobs: **Cloud Run Jobs or Cloud Tasks**

Document processing shouldn't block HTTP requests. Options:
- *Cloud Tasks*: Queue that triggers Cloud Run endpoints. Simple, GCP-native.
- *Cloud Run Jobs*: For longer processing. Can run up to 24 hours.
- *Celery + Redis*: More complex but more control. Defer unless needed.

For MVP, Cloud Tasks â†’ Cloud Run endpoint is simplest.

---

## 2. Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                  FRONTEND                                    â”‚
â”‚                           (Vercel / Next.js 14)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Auth UI   â”‚  â”‚  Dashboard  â”‚  â”‚ Knowledge   â”‚  â”‚   Quiz Interface    â”‚ â”‚
â”‚  â”‚  (Supabase) â”‚  â”‚   + Gaps    â”‚  â”‚    Map      â”‚  â”‚                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â”‚ HTTPS / WebSocket
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                   BACKEND                                    â”‚
â”‚                            (Cloud Run / FastAPI)                            â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   API Gateway    â”‚  â”‚  Auth Middleware â”‚  â”‚    Rate Limiting         â”‚  â”‚
â”‚  â”‚   (FastAPI)      â”‚  â”‚  (Supabase JWT)  â”‚  â”‚    (Redis/Memory)        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                                                                 â”‚
â”‚           â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         SERVICE LAYER                                â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  Document   â”‚  â”‚  Knowledge  â”‚  â”‚    Quiz     â”‚  â”‚    Gap     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  Service    â”‚  â”‚   Service   â”‚  â”‚   Service   â”‚  â”‚  Analyzer  â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                                                                 â”‚
â”‚           â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         AI PIPELINE                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚   Parser    â”‚  â”‚  Extractor  â”‚  â”‚  Generator  â”‚  â”‚  Evaluator â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ (PDF/Image) â”‚  â”‚ (Knowledge) â”‚  â”‚   (Quiz)    â”‚  â”‚ (Response) â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚                           â”‚
         â–¼                      â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Supabase       â”‚  â”‚   Cloud Tasks       â”‚  â”‚      Claude API             â”‚
â”‚  Storage        â”‚  â”‚   (Job Queue)       â”‚  â”‚      (+ OpenAI fallback)    â”‚
â”‚  (Files)        â”‚  â”‚                     â”‚  â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚
         â”‚                      â”‚
         â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              SUPABASE                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚     PostgreSQL      â”‚  â”‚    Auth Service     â”‚  â”‚   Realtime         â”‚   â”‚
â”‚  â”‚  (+ pgvector)       â”‚  â”‚                     â”‚  â”‚   (future)         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core User Journey: Syllabus Upload â†’ Knowledge Map

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User    â”‚     â”‚ Frontend â”‚     â”‚ Backend  â”‚     â”‚  Queue   â”‚     â”‚   AI     â”‚
â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚ Pipeline â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚ Upload PDF     â”‚                â”‚                â”‚                â”‚
     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚ POST /documentsâ”‚                â”‚                â”‚
     â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚ Store file     â”‚                â”‚
     â”‚                â”‚                â”‚ (Supabase)     â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚ Queue job      â”‚                â”‚
     â”‚                â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚  202 Accepted  â”‚                â”‚                â”‚
     â”‚                â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚  "Processing"  â”‚                â”‚                â”‚                â”‚
     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚ Process job    â”‚
     â”‚                â”‚                â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚  1. Fetch PDF  â”‚
     â”‚                â”‚                â”‚                â”‚  2. Claude     â”‚
     â”‚                â”‚                â”‚                â”‚     Vision     â”‚
     â”‚                â”‚                â”‚                â”‚  3. Extract    â”‚
     â”‚                â”‚                â”‚                â”‚     structure  â”‚
     â”‚                â”‚                â”‚                â”‚  4. Generate   â”‚
     â”‚                â”‚                â”‚                â”‚     knowledge  â”‚
     â”‚                â”‚                â”‚                â”‚     map        â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚  Store results â”‚                â”‚
     â”‚                â”‚                â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚ Poll/Subscribe â”‚                â”‚                â”‚
     â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚  Knowledge Map â”‚                â”‚                â”‚
     â”‚                â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
     â”‚  Display Map   â”‚                â”‚                â”‚                â”‚
     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚                â”‚
```

---

## 3. Build vs. Buy Decisions

| Component | Decision | Reasoning |
|-----------|----------|-----------|
| **Authentication** | ğŸ›’ BUY (Supabase Auth) | Security-critical, solved problem, not differentiating |
| **Database hosting** | ğŸ›’ BUY (Supabase) | Ops burden not worth it for MVP |
| **File storage** | ğŸ›’ BUY (Supabase Storage) | Commodity infrastructure |
| **PDF text extraction** | ğŸ”¨ BUILD (PyMuPDF + Claude Vision) | Claude Vision handles images/scans; PyMuPDF for clean PDFs. No need for separate OCR service |
| **Knowledge extraction** | ğŸ”¨ BUILD (custom prompts) | **Core differentiator**â€”your prompt engineering and schema design IS the product |
| **Quiz generation** | ğŸ”¨ BUILD (custom prompts) | Core differentiator |
| **Gap analysis** | ğŸ”¨ BUILD (custom logic + LLM) | Core differentiator |
| **Email/notifications** | ğŸ›’ BUY (Resend or Supabase) | Start with transactional only, don't build |
| **Analytics** | ğŸ›’ BUY (Vercel Analytics + PostHog) | Free tiers are sufficient |
| **Error monitoring** | ğŸ›’ BUY (Sentry) | Essential, generous free tier |
| **LLM observability** | ğŸ›’ BUY (Langfuse or Helicone) | Critical for debugging AI issues, cost tracking |

### Detailed Build Decisions

**PDF/Image Processing:**
```python
# Your processing logic (simplified)
async def process_document(file_path: str, file_type: str) -> str:
    if file_type == "application/pdf":
        # Try PyMuPDF first (fast, free)
        text = extract_with_pymupdf(file_path)
        if is_mostly_text(text):  # >80% extractable
            return text
        # Fall back to Claude Vision for scanned PDFs
        return await extract_with_claude_vision(file_path)
    
    elif file_type.startswith("image/"):
        # Always use Claude Vision for images
        return await extract_with_claude_vision(file_path)
    
    else:  # Plain text
        return read_file(file_path)
```

This hybrid approach saves money (PyMuPDF is free) while handling scanned documents gracefully.

---

## 4. Data Model

### Entity Relationship Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     users       â”‚       â”‚       spaces        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)         â”‚â”€â”€â”€â”   â”‚ id (PK)             â”‚
â”‚ email           â”‚   â”‚   â”‚ user_id (FK)        â”‚â”€â”€â”
â”‚ name            â”‚   â””â”€â”€>â”‚ name                â”‚  â”‚
â”‚ created_at      â”‚       â”‚ subject             â”‚  â”‚
â”‚ settings (JSON) â”‚       â”‚ semester            â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ created_at          â”‚  â”‚
                          â”‚ settings (JSON)     â”‚  â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                    â”‚              â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                 â”‚                                 â”‚
                 â–¼                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚            documents                 â”‚           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚ id (PK)                             â”‚           â”‚
â”‚ space_id (FK)                       â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ type (syllabus|material|test)       â”‚
â”‚ original_filename                   â”‚
â”‚ storage_path                        â”‚
â”‚ mime_type                           â”‚
â”‚ extracted_text                      â”‚
â”‚ processing_status                   â”‚
â”‚ processed_at                        â”‚
â”‚ created_at                          â”‚
â”‚ metadata (JSON)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ (syllabus documents generate)
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          knowledge_maps             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)                             â”‚
â”‚ space_id (FK)                       â”‚
â”‚ document_id (FK) (source syllabus)  â”‚
â”‚ version                             â”‚
â”‚ created_at                          â”‚
â”‚ is_active                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ (contains many)
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            topics                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)                             â”‚
â”‚ knowledge_map_id (FK)               â”‚
â”‚ name                                â”‚
â”‚ description                         â”‚
â”‚ sequence_order                      â”‚
â”‚ estimated_date (from syllabus)      â”‚
â”‚ is_milestone                        â”‚
â”‚ parent_topic_id (FK, self-ref)      â”‚â—„â”€â”€â”€â”
â”‚ difficulty_level                    â”‚    â”‚
â”‚ metadata (JSON)                     â”‚â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         â”‚
    â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚topic_dependenciesâ”‚  â”‚    topic_mastery        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)         â”‚   â”‚ id (PK)                 â”‚
â”‚ topic_id (FK)   â”‚   â”‚ user_id (FK)            â”‚
â”‚ depends_on (FK) â”‚   â”‚ topic_id (FK)           â”‚
â”‚ strength        â”‚   â”‚ mastery_level (0-100)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ confidence              â”‚
                      â”‚ last_assessed_at        â”‚
                      â”‚ assessment_count        â”‚
                      â”‚ is_gap                  â”‚
                      â”‚ gap_priority            â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            quizzes                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)                             â”‚
â”‚ space_id (FK)                       â”‚
â”‚ user_id (FK)                        â”‚
â”‚ quiz_type (practice|diagnostic)     â”‚
â”‚ target_topics (FK[])                â”‚
â”‚ created_at                          â”‚
â”‚ completed_at                        â”‚
â”‚ overall_score                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          quiz_questions             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)                             â”‚
â”‚ quiz_id (FK)                        â”‚
â”‚ topic_id (FK)                       â”‚
â”‚ question_type (mcq|short|explain)   â”‚
â”‚ question_text                       â”‚
â”‚ options (JSON, for MCQ)             â”‚
â”‚ correct_answer                      â”‚
â”‚ difficulty                          â”‚
â”‚ sequence_order                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          quiz_responses             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)                             â”‚
â”‚ question_id (FK)                    â”‚
â”‚ user_answer                         â”‚
â”‚ is_correct                          â”‚
â”‚ ai_evaluation (JSON)                â”‚
â”‚ feedback                            â”‚
â”‚ responded_at                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          graded_tests               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)                             â”‚
â”‚ document_id (FK)                    â”‚
â”‚ space_id (FK)                       â”‚
â”‚ test_date                           â”‚
â”‚ total_score                         â”‚
â”‚ max_score                           â”‚
â”‚ ai_analysis (JSON)                  â”‚
â”‚ identified_gaps (topic_id[])        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Schema Decisions

**1. Knowledge maps are versioned:**
```sql
-- When syllabus is re-uploaded or edited, create new version
-- Keep old version for history but mark inactive
ALTER TABLE knowledge_maps ADD COLUMN version INT DEFAULT 1;
ALTER TABLE knowledge_maps ADD COLUMN is_active BOOLEAN DEFAULT true;
```

**2. Topics support hierarchy (for complex subjects):**
```sql
-- Self-referential for subtopics
-- "Calculus" â†’ "Derivatives" â†’ "Chain Rule"
parent_topic_id UUID REFERENCES topics(id)
```

**3. Mastery is per-user, per-topic:**
```sql
-- This is your core "progress" data
-- Updated after every quiz response
CREATE TABLE topic_mastery (
    user_id UUID REFERENCES users(id),
    topic_id UUID REFERENCES topics(id),
    mastery_level INT CHECK (mastery_level BETWEEN 0 AND 100),
    -- ...
    PRIMARY KEY (user_id, topic_id)
);
```

**4. JSON columns for flexibility:**
```sql
-- metadata, ai_evaluation, settings use JSONB
-- Lets you iterate on structure without migrations
-- PostgreSQL JSONB is queryable and indexable
metadata JSONB DEFAULT '{}'::jsonb
```

**âš ï¸ Hard-to-reverse decision:** Your knowledge map schema (topics, dependencies) will shape your entire product. Spend time getting this right. Consider:
- Can topics span multiple syllabi? (I'd say no for MVPâ€”one syllabus = one knowledge map)
- How granular? (Err toward more specific: "Solving quadratic equations" not "Algebra")
- How do you handle syllabus updates mid-semester?

---

## 5. AI Pipeline Design

### Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           AI PIPELINE COMPONENTS                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 1: DOCUMENT INGESTION                                                 â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Upload    â”‚â”€â”€â”€>â”‚   Parse     â”‚â”€â”€â”€>â”‚  Normalize  â”‚â”€â”€â”€>â”‚   Store     â”‚  â”‚
â”‚  â”‚  Handler    â”‚    â”‚  (PyMuPDF/  â”‚    â”‚   Text      â”‚    â”‚  (Supabase) â”‚  â”‚
â”‚  â”‚             â”‚    â”‚   Vision)   â”‚    â”‚             â”‚    â”‚             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚  Models: Claude Haiku (OCR) - cheap, fast for text extraction               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 2: KNOWLEDGE EXTRACTION (Syllabus Only)                               â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Structure  â”‚â”€â”€â”€>â”‚   Topic     â”‚â”€â”€â”€>â”‚ Dependency  â”‚â”€â”€â”€>â”‚  Timeline   â”‚  â”‚
â”‚  â”‚  Detection  â”‚    â”‚ Extraction  â”‚    â”‚  Inference  â”‚    â”‚  Mapping    â”‚  â”‚
â”‚  â”‚             â”‚    â”‚             â”‚    â”‚             â”‚    â”‚             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚  Models: Claude Sonnet - best balance of quality/cost for complex reasoning â”‚
â”‚                                                                             â”‚
â”‚  Output: Structured JSON matching your topics schema                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 3: MATERIAL INTEGRATION (Course materials, worksheets)                â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚   Match to  â”‚â”€â”€â”€>â”‚   Enrich    â”‚â”€â”€â”€>â”‚   Update    â”‚                     â”‚
â”‚  â”‚   Topics    â”‚    â”‚   Topics    â”‚    â”‚  Knowledge  â”‚                     â”‚
â”‚  â”‚             â”‚    â”‚ (examples,  â”‚    â”‚    Map      â”‚                     â”‚
â”‚  â”‚             â”‚    â”‚  context)   â”‚    â”‚             â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                             â”‚
â”‚  Models: Claude Haiku - simpler classification task                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 4: ASSESSMENT (Graded tests â†’ Gap identification)                     â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Extract   â”‚â”€â”€â”€>â”‚   Map to    â”‚â”€â”€â”€>â”‚  Analyze    â”‚â”€â”€â”€>â”‚   Update    â”‚  â”‚
â”‚  â”‚  Q&A Pairs  â”‚    â”‚   Topics    â”‚    â”‚   Errors    â”‚    â”‚  Mastery    â”‚  â”‚
â”‚  â”‚             â”‚    â”‚             â”‚    â”‚             â”‚    â”‚   + Gaps    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚  Models: Claude Sonnet - nuanced understanding of student errors            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 5: QUIZ GENERATION                                                    â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚   Select    â”‚â”€â”€â”€>â”‚  Generate   â”‚â”€â”€â”€>â”‚  Validate   â”‚                     â”‚
â”‚  â”‚   Topics    â”‚    â”‚  Questions  â”‚    â”‚  Quality    â”‚                     â”‚
â”‚  â”‚ (gap-based) â”‚    â”‚             â”‚    â”‚             â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                             â”‚
â”‚  Models: Claude Sonnet - quality questions require reasoning                â”‚
â”‚                                                                             â”‚
â”‚  Strategy: Generate 5-7 questions, validate, cache for reuse               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 6: RESPONSE EVALUATION                                                â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Receive   â”‚â”€â”€â”€>â”‚  Evaluate   â”‚â”€â”€â”€>â”‚  Generate   â”‚â”€â”€â”€>â”‚   Update    â”‚  â”‚
â”‚  â”‚   Answer    â”‚    â”‚ Correctness â”‚    â”‚  Feedback   â”‚    â”‚  Mastery    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚  Models: Claude Haiku - MCQ is simple; Sonnet for open-ended               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example Prompts (Your Core IP)

**Knowledge Extraction Prompt (Stage 2):**
```python
SYLLABUS_EXTRACTION_PROMPT = """
You are analyzing a course syllabus to extract a structured knowledge map.

<syllabus>
{extracted_text}
</syllabus>

Extract the following as JSON:

1. **topics**: Array of learning topics/concepts
   - name: Clear, specific topic name
   - description: What students should understand
   - sequence_order: Order in the course (1, 2, 3...)
   - estimated_week: When this is covered (week number)
   - is_milestone: Is this a major exam/project? (boolean)
   - difficulty_level: 1-5 scale
   - parent_topic: Name of parent topic if this is a subtopic, null otherwise

2. **dependencies**: Array of topic relationships
   - topic: Topic name
   - depends_on: Array of prerequisite topic names
   - strength: How strong the dependency is (required|helpful|related)

3. **timeline**: Key dates
   - date: ISO date string
   - event: What happens (exam, project due, etc.)
   - related_topics: Array of relevant topic names

Be specific with topic names. "Solving quadratic equations by factoring" is better 
than "Algebra". Extract ALL assessments as milestones.

Respond ONLY with valid JSON matching this schema:
{schema}
"""
```

**Gap Analysis Prompt (Stage 4):**
```python
GAP_ANALYSIS_PROMPT = """
Analyze this graded test to identify knowledge gaps.

<test_content>
{extracted_test_content}
</test_content>

<knowledge_map>
{knowledge_map_json}
</knowledge_map>

For each question the student got wrong or partially wrong:
1. Identify which topic(s) from the knowledge map it tests
2. Analyze the specific misconception or gap
3. Rate severity (critical|moderate|minor)
4. Suggest what to review

Return JSON:
{
  "gaps": [
    {
      "topic_id": "uuid",
      "topic_name": "string",
      "misconception": "What the student seems to misunderstand",
      "severity": "critical|moderate|minor",
      "evidence": "Quote from test showing the error",
      "remediation": "What to study/practice"
    }
  ],
  "overall_assessment": "Brief summary of student's understanding"
}
"""
```

### Pipeline Implementation Pattern

```python
# services/ai_pipeline.py

from anthropic import Anthropic
from typing import Literal

class AIPipeline:
    def __init__(self):
        self.client = Anthropic()
        
    async def run_stage(
        self,
        stage: Literal["extract", "quiz_gen", "evaluate"],
        input_data: dict,
        model: str = "claude-sonnet-4-20250514"
    ) -> dict:
        """
        Generic stage runner with:
        - Retry logic
        - Cost tracking
        - Structured output validation
        """
        prompt = self._get_prompt(stage, input_data)
        
        # Track token usage for cost monitoring
        response = await self.client.messages.create(
            model=model,
            max_tokens=4096,
            messages=[{"role": "user", "content": prompt}]
        )
        
        # Log to observability (Langfuse/Helicone)
        self._log_usage(stage, response.usage)
        
        # Parse and validate JSON response
        return self._parse_response(stage, response.content[0].text)
    
    def _select_model(self, stage: str, complexity: str) -> str:
        """Choose model based on task complexity and cost."""
        model_map = {
            ("extract_text", "any"): "claude-haiku-4-5-20251001",
            ("extract_knowledge", "any"): "claude-sonnet-4-20250514",
            ("evaluate", "mcq"): "claude-haiku-4-5-20251001",
            ("evaluate", "open"): "claude-sonnet-4-20250514",
            ("quiz_gen", "any"): "claude-sonnet-4-20250514",
        }
        return model_map.get((stage, complexity), "claude-sonnet-4-20250514")
```

---

## 6. Cost Estimation Approach

### Per-User Cost Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MONTHLY COST PER ACTIVE USER                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Assumptions:
- 1 syllabus upload (beginning of semester)
- 4 material uploads/month
- 2 graded test uploads/month  
- 20 quizzes taken/month (5 questions each = 100 questions)
- 100 quiz responses evaluated/month

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operation          â”‚ Model        â”‚ Tokens/op  â”‚ Ops/mo   â”‚ Cost/mo       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Syllabus extract   â”‚ Sonnet       â”‚ ~8K out    â”‚ 0.25*    â”‚ $0.12         â”‚
â”‚ Material process   â”‚ Haiku        â”‚ ~2K out    â”‚ 4        â”‚ $0.08         â”‚
â”‚ Test analysis      â”‚ Sonnet       â”‚ ~4K out    â”‚ 2        â”‚ $0.60         â”‚
â”‚ Quiz generation    â”‚ Sonnet       â”‚ ~3K out    â”‚ 5**      â”‚ $0.45         â”‚
â”‚ Response eval      â”‚ Haiku        â”‚ ~500 out   â”‚ 100      â”‚ $0.50         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL              â”‚              â”‚            â”‚          â”‚ ~$1.75/user   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

* Amortized across ~4 months per semester
** 20 quizzes but with caching, only ~5 new generations needed

Pricing used (as of late 2024):
- Claude Sonnet: $3/1M input, $15/1M output
- Claude Haiku: $0.25/1M input, $1.25/1M output
```

### Cost Control Strategies

**1. Model Selection by Task:**
```python
# Map task complexity to model
MODEL_ROUTING = {
    "ocr_extraction": "haiku",      # Simple text extraction
    "mcq_evaluation": "haiku",      # Binary correct/incorrect
    "knowledge_extraction": "sonnet", # Complex reasoning
    "quiz_generation": "sonnet",     # Creative + accurate
    "gap_analysis": "sonnet",        # Nuanced understanding
}
```

**2. Aggressive Caching:**
```python
# Cache quiz questions by topic
# If topic hasn't changed and we have 10+ questions, don't regenerate
async def get_quiz_questions(topic_id: str, count: int) -> list:
    cached = await cache.get(f"quiz_questions:{topic_id}")
    if cached and len(cached) >= count:
        return random.sample(cached, count)
    
    # Generate new questions, add to cache
    new_questions = await ai_pipeline.generate_questions(topic_id, count=10)
    await cache.set(f"quiz_questions:{topic_id}", new_questions, ttl=86400*7)
    return new_questions[:count]
```

**3. Batch Processing:**
```python
# When processing multiple materials, batch into single API call
async def process_materials_batch(materials: list[Document]) -> list:
    combined_text = "\n---\n".join([m.extracted_text for m in materials])
    # Single API call instead of N calls
    result = await ai_pipeline.classify_materials_batch(combined_text)
    return result
```

**4. Token Budgets:**
```python
# Hard limits per operation
TOKEN_LIMITS = {
    "syllabus_extraction": 10000,
    "quiz_generation": 4000,
    "response_evaluation": 1000,
}

# Per-user monthly budget
USER_MONTHLY_BUDGET = 50000  # tokens
```

**5. Monitoring & Alerts:**
```python
# Track costs in real-time with Langfuse or custom
@track_cost
async def generate_quiz(topic_ids: list[str]) -> Quiz:
    ...

# Alert if user exceeds expected usage
if user.monthly_token_usage > USER_MONTHLY_BUDGET * 0.8:
    await notify_admin(f"User {user.id} at 80% budget")
```

### Infrastructure Costs (Monthly)

| Service | Tier | Est. Cost |
|---------|------|-----------|
| Supabase | Pro | $25 |
| Vercel | Pro | $20 |
| Cloud Run | Pay-per-use | $10-30 |
| Sentry | Free | $0 |
| Langfuse | Free/Hobby | $0-25 |
| **Total Fixed** | | **~$55-100/mo** |

At $1.75 AI cost per user + ~$75 fixed costs:
- 50 users: $162/mo ($3.25/user)
- 200 users: $425/mo ($2.12/user)
- 1000 users: $1,825/mo ($1.83/user)

---

## 7. MVP Cut Decisions

### What to Build for MVP

| Feature | Include? | Reasoning |
|---------|----------|-----------|
| Account creation | âœ… Yes | Core requirement |
| Spaces (per class) | âœ… Yes | Essential organization |
| Syllabus upload (PDF/image/text) | âœ… Yes | Core value prop |
| Knowledge map display | âœ… Yes | Core value prop |
| Material uploads | âœ… Yes | Enriches knowledge map |
| Graded test upload + gap ID | âœ… Yes | High value, differentiating |
| Basic quizzes (MCQ) | âœ… Yes | Immediate value |
| Progress dashboard | âœ… Yes | Shows value over time |
| Google OAuth | âœ… Yes | Students expect it |

### What to Defer (and Why)

| Feature | Why It's Tempting | Why to Defer |
|---------|-------------------|--------------|
| **Mobile app** | Students are on phones | PWA gives you 80% of mobile value. Native apps are 3x the maintenance. |
| **Open-ended quiz responses** | More pedagogically valuable | Evaluation is harder, costs more. Start with MCQ, add later. |
| **Parent dashboard** | Part of your vision | Different user, different needs. Nail student experience first. |
| **Study schedule generation** | Feels "smart" | Complex to get right. Manual timeline from syllabus is enough for MVP. |
| **Collaborative features** | Study groups are real | Multi-user is hard. Single-player first. |
| **Advanced visualizations** | Knowledge graphs look cool | Simple list/timeline is fine. Don't bikeshed on D3.js. |
| **Multiple choice answer explanations** | Better learning | Doubles generation cost. Add after you validate core. |
| **Spaced repetition scheduling** | Proven effective | Requires more data to do well. V2 feature. |
| **Integration with LMS (Canvas, etc.)** | Easier onboarding | API work is significant. Manual upload is fine for MVP. |
| **Real-time progress updates** | Feels modern | Polling every 30s is fine. WebSockets add complexity. |
| **Custom branding/white-label** | Future B2B play | Not relevant for consumer MVP. |
| **Offline mode** | Students study anywhere | Service worker complexity not worth it yet. |
| **Multi-language support** | Bigger market | i18n is a tax on every feature. English first. |

### The "One More Thing" Trap

These features feel small but aren't:
- **"Just add dark mode"** â†’ Theme system, testing, edge cases
- **"Let users edit the knowledge map"** â†’ Conflict resolution, versioning, UI complexity
- **"Show estimated study time"** â†’ Needs calibration data you don't have
- **"Send reminder notifications"** â†’ Notification infrastructure, preferences, timing logic

### Your MVP Success Metric

Before building anything else, prove:
> "Students who upload a syllabus and take 3+ quizzes return within 7 days"

If this isn't happening, adding features won't help.

---

## Summary: First 30 Days Roadmap

```
Week 1: Foundation
â”œâ”€â”€ Set up Supabase (db + auth + storage)
â”œâ”€â”€ Set up Next.js with shadcn/ui
â”œâ”€â”€ Basic auth flow (sign up, log in, Google OAuth)
â””â”€â”€ Deploy to Vercel + Cloud Run (CI/CD)

Week 2: Core Upload Flow
â”œâ”€â”€ Create space flow
â”œâ”€â”€ File upload to Supabase storage
â”œâ”€â”€ Background job: PDF â†’ text extraction
â”œâ”€â”€ Background job: Syllabus â†’ knowledge map
â””â”€â”€ Display knowledge map (simple list view)

Week 3: Quizzes
â”œâ”€â”€ Quiz generation from topics
â”œâ”€â”€ MCQ quiz interface
â”œâ”€â”€ Response evaluation (Haiku)
â”œâ”€â”€ Basic mastery tracking
â””â”€â”€ Progress dashboard (v1)

Week 4: Gap Analysis
â”œâ”€â”€ Graded test upload
â”œâ”€â”€ Gap identification
â”œâ”€â”€ Gap display on dashboard
â”œâ”€â”€ Quiz targeting gaps
â””â”€â”€ Polish, bugs, user testing
```

---

## Appendix: Key Technical Snippets

### Supabase Schema (SQL)

```sql
-- Enable pgvector for future embeddings
create extension if not exists vector;

-- Core tables
create table spaces (
    id uuid primary key default gen_random_uuid(),
    user_id uuid references auth.users(id) on delete cascade,
    name text not null,
    subject text,
    semester text,
    created_at timestamptz default now(),
    settings jsonb default '{}'::jsonb
);

create table documents (
    id uuid primary key default gen_random_uuid(),
    space_id uuid references spaces(id) on delete cascade,
    type text check (type in ('syllabus', 'material', 'test')),
    original_filename text not null,
    storage_path text not null,
    mime_type text,
    extracted_text text,
    processing_status text default 'pending',
    processed_at timestamptz,
    created_at timestamptz default now(),
    metadata jsonb default '{}'::jsonb
);

create table knowledge_maps (
    id uuid primary key default gen_random_uuid(),
    space_id uuid references spaces(id) on delete cascade,
    document_id uuid references documents(id),
    version int default 1,
    is_active boolean default true,
    created_at timestamptz default now()
);

create table topics (
    id uuid primary key default gen_random_uuid(),
    knowledge_map_id uuid references knowledge_maps(id) on delete cascade,
    parent_topic_id uuid references topics(id),
    name text not null,
    description text,
    sequence_order int,
    estimated_date date,
    is_milestone boolean default false,
    difficulty_level int check (difficulty_level between 1 and 5),
    metadata jsonb default '{}'::jsonb
);

create table topic_mastery (
    id uuid primary key default gen_random_uuid(),
    user_id uuid references auth.users(id) on delete cascade,
    topic_id uuid references topics(id) on delete cascade,
    mastery_level int default 0 check (mastery_level between 0 and 100),
    confidence numeric(3,2) default 0,
    last_assessed_at timestamptz,
    assessment_count int default 0,
    is_gap boolean default false,
    gap_priority int,
    unique (user_id, topic_id)
);

-- Row Level Security
alter table spaces enable row level security;
create policy "Users can only see their own spaces"
    on spaces for all using (auth.uid() = user_id);

-- Similar policies for other tables...
```

### FastAPI Auth Middleware

```python
# middleware/auth.py
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer
from supabase import create_client
import os

security = HTTPBearer()
supabase = create_client(os.environ["SUPABASE_URL"], os.environ["SUPABASE_KEY"])

async def get_current_user(token: str = Depends(security)):
    try:
        user = supabase.auth.get_user(token.credentials)
        return user
    except Exception:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid authentication credentials"
        )
```

### Document Processing Job

```python
# jobs/process_document.py
from anthropic import Anthropic
import fitz  # PyMuPDF

async def process_document(document_id: str):
    # 1. Fetch document metadata
    doc = await db.documents.get(document_id)
    
    # 2. Download file from storage
    file_bytes = await storage.download(doc.storage_path)
    
    # 3. Extract text
    if doc.mime_type == "application/pdf":
        text = extract_pdf_text(file_bytes)
        if not text or len(text) < 100:  # Probably scanned
            text = await extract_with_vision(file_bytes)
    elif doc.mime_type.startswith("image/"):
        text = await extract_with_vision(file_bytes)
    else:
        text = file_bytes.decode("utf-8")
    
    # 4. Update document
    await db.documents.update(document_id, {
        "extracted_text": text,
        "processing_status": "extracted"
    })
    
    # 5. If syllabus, trigger knowledge extraction
    if doc.type == "syllabus":
        await extract_knowledge_map(document_id)

def extract_pdf_text(file_bytes: bytes) -> str:
    doc = fitz.open(stream=file_bytes, filetype="pdf")
    text = ""
    for page in doc:
        text += page.get_text()
    return text.strip()

async def extract_with_vision(file_bytes: bytes) -> str:
    client = Anthropic()
    # Use Claude's vision to extract text from images/scanned PDFs
    response = await client.messages.create(
        model="claude-haiku-4-5-20251001",
        max_tokens=4096,
        messages=[{
            "role": "user",
            "content": [
                {"type": "image", "source": {"type": "base64", "media_type": "image/png", "data": base64.b64encode(file_bytes).decode()}},
                {"type": "text", "text": "Extract all text from this document. Preserve structure and formatting where possible."}
            ]
        }]
    )
    return response.content[0].text
```

---